<h1>jason-gross.bib</h1><a name="Bauer:2017:HLF:3018610.3018615"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#Bauer:2017:HLF:3018610.3018615">Bauer:2017:HLF:3018610.3018615</a>,
  author = {Bauer, Andrej and Gross, Jason and Lumsdaine, Peter LeFanu and Shulman, Michael and Sozeau, Matthieu and Spitters, Bas},
  booktitle = {Proceedings of the \href{http://cpp2017.mpi-sws.org/}{6th ACM SIGPLAN Conference on Certified Programs and Proofs}\},
  title = {The {HoTT} Library: A Formalization of Homotopy Type Theory in {C}oq},
  year = {2017},
  address = {New York, NY, USA},
  month = {January},
  pages = {164--172},
  publisher = {ACM},
  series = {CPP 2017},
  abstract = {We report on the development of the \emph{\{HoTT} library}, a formalization of homotopy type theory in the {Coq} proof assistant. It formalizes most of basic homotopy type theory, including univalence, higher inductive types, and significant amounts of synthetic homotopy theory, as well as category theory and modalities. The library has been used as a basis for several independent developments. We discuss the decisions that led to the design of the library, and we comment on the interaction of homotopy type theory with recently introduced features of {Coq}, such as universe polymorphism and private inductive types.},
  acmid = {3018615},
  doi = {10.1145/3018610.3018615},
  eprint = {1610.04591},
  isbn = {978-1-4503-4705-1},
  keywords = {Coq, Higher inductive types, Homotopy type theory, Univalent foundations, Universe polymorphism},
  location = {Paris, France},
  numpages = {9},
  oai2identifier = {1610.04591},
  url = {<a href="https://jasongross.github.io/papers/2017-HoTT-formalization.pdf">https://jasongross.github.io/papers/2017-HoTT-formalization.pdf</a>}
}
</code></pre>

<a name="adt-synthesis"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#adt-synthesis">adt-synthesis</a>,
  author = {Ben Delaware and Cl\'ement Pit--Claudel and Jason Gross and Adam Chlipala},
  booktitle = {Proceedings of the \href{http://popl.mpi-sws.org/2015/}{42nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'15)}\},
  title = {Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant},
  year = {2015},
  month = {January},
  abstract = {We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of \textit{query structures} -- abstract data types with SQL-like query and insert operations. Fiat includes a library for writing specifications of query structures in SQL-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a set of tactics for automating the refinement of these specifications into efficient, correct-by-construction OCaml code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of SQL indexes, data structures capturing useful views of the abstract data. We conclude by speculating on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.},
  doi = {10.1145/2775051.2677006},
  url = {<a href="https://jasongross.github.io/papers/2015-adt-synthesis.pdf">https://jasongross.github.io/papers/2015-adt-synthesis.pdf</a>}
}
</code></pre>

<a name="fiat-crypto"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#fiat-crypto">fiat-crypto</a>,
  author = {Andres Erbsen and Jade Philipoom and Jason Gross and Robert Sloan and Adam Chlipala},
  booktitle = {Proceedings of the \href{https://www.ieee-security.org/TC/SP2019/}{40th IEEE Symposium on Security and Privacy (S\&P'19)}\},
  title = {Simple High-Level Code For Cryptographic Arithmetic -- With Proofs, Without Compromises},
  year = {2019},
  month = {May},
  abstract = {We introduce a new approach for implementing cryptographic arithmetic in short high-level code with machine-checked proofs of functional correctness.
    We further demonstrate that simple partial evaluation is sufficient to transform into the fastest-known C code, breaking the decades-old pattern that the only fast implementations are those whose instruction-level steps were written out by hand.
    
    These techniques were used to build an elliptic-curve library that achieves competitive performance for 80 prime fields and multiple CPU architectures, showing that implementation and proof effort scales with the number and complexity of conceptually different algorithms, not their use cases.
    As one outcome, we present the first verified high-performance implementation of P-256, the most widely used elliptic curve.
    Implementations from our library were included in BoringSSL to replace existing specialized code, for inclusion in several large deployments for Chrome, Android, and CloudFlare.},
  doi = {10.1145/3421473.3421477},
  url = {<a href="https://jasongross.github.io/papers/2019-fiat-crypto-ieee-sp.pdf">https://jasongross.github.io/papers/2019-fiat-crypto-ieee-sp.pdf</a>}
}
</code></pre>

<a name="hott-hott-and-category-coq-experience"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#hott-hott-and-category-coq-experience">hott-hott-and-category-coq-experience</a>,
  author = {Jason Gross},
  month = {July},
  note = {Presented at \href{http://icms2016.zib.de/}{The 5th International Congress on Mathematical Software (ICMS 2016)}\},
  title = {The {HoTT}/{HoTT} Library in {C}oq: Designing for Speed},
  year = {2016},
  abstract = {The HoTT/HoTT library is one of the major Coq libraries exploring univalent foundations and homotopy type theory, the other being UniMath. The library includes formalization of the basic type formers, some axiomatic higher inductive types including the circle, the interval, suspensions, and quotients, a formalization of modalities (reflective subtoposes) using modules as a way to quantify over all universe levels, formalizations of Cantor spaces and the surreals, the basic theory of h-levels, and a significant amount of category theory centered around comma categories and functoriality of various constructions involving comma categories. A significant amount of work has gone into ensuring that the library compiles quickly. This talk will discuss the various constructions in the HoTT library, as well as the design choices and features, both of Coq and of univalent type theory, which allow our library to compile and typecheck quickly.},
  url = {<a href="https://jasongross.github.io/presentations/icms-2016/hott-hott-and-category-coq-experience.pdf">https://jasongross.github.io/presentations/icms-2016/hott-hott-and-category-coq-experience.pdf</a>}
}
</code></pre>

<a name="coqpl-15-coq-bug-minimizer"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#coqpl-15-coq-bug-minimizer">coqpl-15-coq-bug-minimizer</a>,
  author = {Jason Gross},
  month = {January},
  note = {Presented at \href{https://coqpl.cs.washington.edu/2014/07/31/}{The First International Workshop on Coq for PL (CoqPL'15)}\},
  title = {Coq Bug Minimizer},
  year = {2015},
  abstract = {Are bugs the bane of your existence? Do you dread Coq upgrades, because they mean you'll have to spend days tracking down subtle failures deep in your developments? Have you ever hit an anomaly that just wouldn't go away, and wished you understood what triggered it? Have you ever been tormented by two blocks of code that looked identical, but behaved differently? Do you wish you submit more helpful error reports, but don't want to put in the time to construct minimal examples? If you answered ``yes'' to any of these questions, then the Coq Bug Minimizer is for you! Clone your own copy at \url{https://github.com/JasonGross/coq-bug-finder}.},
  url = {<a href="https://jasongross.github.io/papers/2015-coq-bug-minimizer.pdf">https://jasongross.github.io/papers/2015-coq-bug-minimizer.pdf</a>}
}
</code></pre>

<a name="jgross-masters-thesis"></a>
<pre class="language-bibtex"><code>@mastersthesis{<a href="{{ "/publications/" | relative_url }}#jgross-masters-thesis">jgross-masters-thesis</a>,
  author = {Jason Gross},
  school = {Massachusetts Institute of Technology},
  title = {An Extensible Framework for Synthesizing Efficient, Verified Parsers},
  year = {2015},
  month = {September},
  abstract = {Parsers have a long history in computer science. This thesis proposes a novel approach to synthesizing efficient, verified parsers by refinement, and presents a demonstration of this approach in the Fiat framework by synthesizing a parser for arithmetic expressions. The benefits of this framework may include more flexibility in the parsers that can be described, more control over the low-level details when necessary for performance, and automatic or mostly automatic correctness proofs.},
  url = {<a href="https://jasongross.github.io/papers/2015-jgross-thesis.pdf">https://jasongross.github.io/papers/2015-jgross-thesis.pdf</a>}
}
</code></pre>

<a name="2014-msr-x86proved-io"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#2014-msr-x86proved-io">2014-msr-x86proved-io</a>,
  author = {Jason Gross},
  month = {August},
  note = {Presented at Microsoft Research, Cambridge, UK},
  title = {Presentation: Input, Output, and Automation in x86 Proved},
  year = {2014},
  abstract = {The x86proved project can now verify assembly programs with input and output! The code-reasoning throughout the project is now mostly automatic. Although not yet push-button verification (specification-level reasoning, in particular, leaves a lot to be desired) these tactics make a significant step towards that goal. This presentation will cover: \\ • some programs whose I/O behaviour has been verified (including a simplified version of the \texttt{echo} command-line tool) \\ • the new automation for fully automatic correctness proofs of Hoare-triple rules for basic instructions \\ • the new automation for applying Hoare rules for assembly instructions automatically \\ • the basics of how we're specifying and verifying the I/O behaviour of programs},
  day = {20},
  url = {<a href="https://jasongross.github.io/presentations/msr-2014-final-talk/input-output-and-automation-in-x86proved.pdf">https://jasongross.github.io/presentations/msr-2014-final-talk/input-output-and-automation-in-x86proved.pdf</a>}
}
</code></pre>

<a name="Gross2014a-coq-wishlist"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2014a-coq-wishlist">Gross2014a-coq-wishlist</a>,
  author = {Jason Gross},
  month = {January},
  title = {\{J}ason {G}ross' Wishlist for {C}oq},
  year = {2014},
  url = {<a href="https://jasongross.github.io/presentations/coq-8.6-wishlist/jgross-coq-8-6-wishlist-no-pause.pdf">https://jasongross.github.io/presentations/coq-8.6-wishlist/jgross-coq-8-6-wishlist-no-pause.pdf</a>}
}
</code></pre>

<a name="Gross2014b-popl-minute-madness"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2014b-popl-minute-madness">Gross2014b-popl-minute-madness</a>,
  author = {Jason Gross},
  month = {January},
  note = {Presented at the \href{http://popl.mpi-sws.org/2014/}{41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'14)}\},
  title = {\{POPL}: Minute Madness: Category Theory in {C}oq, and Program Synthesis},
  year = {2014},
  url = {<a href="https://jasongross.github.io/presentations/popl-2014-minute-madness/jason-gross-minute-madness.pdf">https://jasongross.github.io/presentations/popl-2014-minute-madness/jason-gross-minute-madness.pdf</a>}
}
</code></pre>

<a name="Gross2014c-coq-workshop-proposal"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2014c-coq-workshop-proposal">Gross2014c-coq-workshop-proposal</a>,
  author = {Jason Gross},
  month = {April},
  note = {Presented at the \href{http://www.easychair.org/smart-program/VSL2014/Coq-index.html}{6th Coq Workshop}\},
  title = {Presentation Proposal for Three Neat Tricks in {C}oq 8.5},
  year = {2014},
  abstract = {Coq 8.5 has a number of new features. It has more powerful universe polymorphism support. It allows tactics to be run at interpretation to construct other terms. The ability to switch from Gallina to Ltac in arbitrary locations nicely complements the \texttt{constr:}~notation permitting the switch from Ltac to Gallina in tactics, and opens up many new possibilities. I propose to present three tricks involving these new features: tactics in terms allows the construction of tactics that recurse under binders; tactics in terms together with typeclasses allows overloading notations based on the type of their arguments; and there is a way to talk about universe levels explicitly, helped along by tactics in terms.},
  day = {11},
  url = {<a href="https://jasongross.github.io/presentations/coq-workshop-2014/coq-workshop-proposal-tactics-in-terms.pdf">https://jasongross.github.io/presentations/coq-workshop-2014/coq-workshop-proposal-tactics-in-terms.pdf</a>}
}
</code></pre>

<a name="Gross2018-coq-workshop-proposal"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2018-coq-workshop-proposal">Gross2018-coq-workshop-proposal</a>,
  author = {Jason Gross},
  month = {July},
  note = {Presented at \href{https://coqworkshop2018.inria.fr/}{The Coq Workshop 2018}\},
  title = {Presentation Proposal for Teaching Your Rooster to Crow in {C}\},
  year = {2018},
  abstract = {Coq's notation system is both extremely powerful and confusingly ad-hoc.
    While powerful enough to pretty-print abstract syntax trees in most domain-specific languages, how to do so does not seem to be common knowledge.
    Typical questions arising from such an endeavor might include ``How do I pick notation levels?'', ``Why are these notations clashing?'', ``Which things should be marked as symbols?'', ``How do I use boxes in \texttt{format}?'', and ``How do I get parentheses to show up (only) where I want them to?''
    This interactive presentation aims to serve as a guide to these questions and more, by demonstrating and explaining how to pretty-print subsets of C using only Coq's \texttt{Notation} mechanism.},
  day = {11},
  url = {<a href="https://jasongross.github.io/presentations/coq-workshop-2018/coq-workshop-proposal-notations.pdf">https://jasongross.github.io/presentations/coq-workshop-2018/coq-workshop-proposal-notations.pdf</a>}
}
</code></pre>

<a name="Gross2013a-database-in-categories"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2013a-database-in-categories">Gross2013a-database-in-categories</a>,
  author = {Jason Gross},
  month = {January},
  note = {Presented as a student talk at the \href{http://popl.mpi-sws.org/2013/}{40th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'13)}\},
  title = {Building Database Management on top of Category Theory in {C}oq},
  year = {2013},
  url = {<a href="https://jasongross.github.io/presentations/popl-2013/jgross-student-talk.pdf">https://jasongross.github.io/presentations/popl-2013/jgross-student-talk.pdf</a>}
}
</code></pre>

<a name="Gross2013b-popl-minute-madness"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2013b-popl-minute-madness">Gross2013b-popl-minute-madness</a>,
  author = {Jason Gross},
  month = {January},
  note = {Presented at the \href{http://popl.mpi-sws.org/2013/}{40th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'13)}\},
  title = {\{POPL}: Minute Madness: Database Management on top of Category Theory in {C}oq: Category of Relational Schemas = Category of Categories},
  year = {2013},
  url = {<a href="https://jasongross.github.io/presentations/popl-2013/minute-madness.pdf">https://jasongross.github.io/presentations/popl-2013/minute-madness.pdf</a>}
}
</code></pre>

<a name="Gross2013-csw"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#Gross2013-csw">Gross2013-csw</a>,
  author = {Jason Gross},
  month = {October},
  note = {Presented at the \href{http://projects.csail.mit.edu/csw/2014/index.htm}{2014 MIT CSAIL Student Workshop}\},
  title = {\{CSAIL} Student Workshop 2013: Computational Higher Inductive Types: Computing with Custom Equalities},
  year = {2013},
  url = {<a href="https://jasongross.github.io/presentations/csw-2013/jgross-presentation-no-pause.pdf">https://jasongross.github.io/presentations/csw-2013/jgross-presentation-no-pause.pdf</a>}
}
</code></pre>

<a name="category-coq-experience"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#category-coq-experience">category-coq-experience</a>,
  author = {Jason Gross and Adam Chlipala and David I. Spivak},
  editor = {Gerwin Klein and Ruben Gamboa},
  booktitle = {Proceedings of the \href{http://www.cs.uwyo.edu/~ruben/itp-2014}{5th International Conference on Interactive Theorem Proving (ITP'14)}\},
  title = {Experience Implementing a Performant Category-Theory Library in {C}oq},
  year = {2014},
  month = {July},
  abstract = {We describe our experience implementing a broad category-theory library in Coq. Category theory and computational performance are not usually mentioned in the same breath, but we have needed substantial engineering effort to teach Coq to cope with large categorical constructions without slowing proof script processing unacceptably. In this paper, we share the lessons we have learned about how to represent very abstract mathematical objects and arguments in Coq and how future proof assistants might be designed to better support such reasoning. One particular encoding trick to which we draw attention allows category-theoretic arguments involving \emph{duality} to be internalized in Coq's logic with definitional equality. Ours may be the largest Coq development to date that uses the relatively new Coq version developed by homotopy type theorists, and we reflect on which new features were especially helpful.},
  eprint = {1401.7694},
  arxiv-url = {<a href="https://arxiv.org/abs/1401.7694">https://arxiv.org/abs/1401.7694</a>},
  doi = {10.1007/978-3-319-08970-6_18},
  isbn = {978-3-319-08970-6},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {275--291},
  url = {<a href="https://jasongross.github.io/papers/category-coq-experience-itp-submission-final.pdf">https://jasongross.github.io/papers/category-coq-experience-itp-submission-final.pdf</a>}
}
</code></pre>

<a name="reification-by-parametricity"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#reification-by-parametricity">reification-by-parametricity</a>,
  author = {Jason Gross and Andres Erbsen and Adam Chlipala},
  booktitle = {Proceedings of the \href{https://itp2018.inria.fr/}{9th International Conference on Interactive Theorem Proving (ITP'18)}\},
  title = {Reification by Parametricity: Fast Setup for Proof by Reflection, in Two Lines of {L}tac},
  editor = {Jeremy Avigad and Assia Mahboubi},
  year = {2018},
  month = {July},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {289--305},
  isbn = {978-3-319-94821-8},
  abstract = {We present a new strategy for performing reification in Coq.
    That is, we show how to generate first-class abstract syntax trees from ``native'' terms of Coq's logic, suitable as inputs to verified compilers or procedures in the \emph{proof-by-reflection} style.
    Our new strategy, based on simple generalization of subterms as variables, is straightforward, short, and fast.
    In its pure form, it is only complete for constants and function applications, but ``let'' binders, eliminators, lambdas, and quantifiers can be accommodated through lightweight coding conventions or preprocessing.
    
    We survey the existing methods of reification across multiple Coq metaprogramming facilities, describing various design choices and tricks that can be used to speed them up, as well as various limitations.
    We report benchmarking results for 18 variants, in addition to our own, finding that our own reification outperforms 16 of these methods in all cases, and one additional method in some cases; writing an OCaml plugin is the only method tested to be faster.
    Our method is the most concise of the strategies we considered, reifying terms using only two to four lines of \texttt{Ltac}---beyond lists of the identifiers to reify and their reified variants.
    Additionally, our strategy automatically provides error messages that are no less helpful than Coq's own error messages.},
  doi = {10.1007/978-3-319-94821-8_17},
  url = {<a href="https://jasongross.github.io/papers/2018-reification-by-parametricity-itp-camera-ready.pdf">https://jasongross.github.io/papers/2018-reification-by-parametricity-itp-camera-ready.pdf</a>}
}
</code></pre>

<a name="Lake2011"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#Lake2011">Lake2011</a>,
  author = {Brenden M. Lake and Ruslan Salakhutdinov and Jason Gross and Joshua B. Tenenbaum},
  booktitle = {Proceedings of the \href{https://web.archive.org/web/20160823113042/http://cognitivesciencesociety.org/conference2011/index.html}{33rd Annual Conference of the Cognitive Science Society}\},
  title = {One shot learning of simple visual concepts},
  year = {2011},
  abstract = {People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the sharing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich internal part structure, yet they are particularly tractable for computational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing state-of-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data.},
  url = {<a href="https://jasongross.github.io/papers/LakeEtAl2011CogSci.pdf">https://jasongross.github.io/papers/LakeEtAl2011CogSci.pdf</a>}
}
</code></pre>

<a name="coqpl-15-ltac-profiler"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#coqpl-15-ltac-profiler">coqpl-15-ltac-profiler</a>,
  author = {Tobias Tebbi and Jason Gross},
  month = {January},
  note = {Presented at \href{https://coqpl.cs.washington.edu/2014/07/31/}{The First International Workshop on Coq for PL (CoqPL'15)}\},
  title = {A Profiler for {L}tac},
  year = {2015},
  abstract = {We present a simple profiler for the Ltac tactic language of the Coq Proof Assistent. It measures the time spent in invocations of primitive tactics as well as tactics defined in Ltac and their inner invocations. The profiler is controlled using Vernacular commands and prints an aggregated view that differentiates between tactic invocations depending on their call tree location.},
  url = {<a href="https://jasongross.github.io/papers/2015-ltac-profiler.pdf">https://jasongross.github.io/papers/2015-ltac-profiler.pdf</a>}
}
</code></pre>

<a name="Evaluation2021Huhmann"></a>
<pre class="language-bibtex"><code>@article{<a href="{{ "/publications/" | relative_url }}#Evaluation2021Huhmann">Evaluation2021Huhmann</a>,
  author = {Linden B. Huhmann and Charles F. Harvey and Jason Gross and Anjal Uddin and Imtiaz Choudhury and Kazi M. Ahmed and John M. Duxbury and Benjamin Bostick and Alexander {van Geen}\},
  journal = {Geoderma},
  title = {Evaluation of a field kit for testing arsenic in paddy soil contaminated by irrigation water},
  year = {2021},
  month = {January},
  issn = {0016-7061},
  pages = {114755},
  volume = {382},
  abstract = {Rice is the primary crop in Bangladesh and rice yield is diminished due to the buildup of arsenic (As) in soil from irrigation with high-As groundwater. Soil testing with an inexpensive kit could help farmers target high-As soil for mitigation or decide to switch to a different crop that is less sensitive to As in soil. A total of 3240 field kit measurements of As in 0.5 g of fresh soil added to 50 mL of water were compared with total soil As concentrations measured on oven-dried homogenized soil by X-ray fluorescence (XRF). For sets of 12 soil samples collected within a series of rice fields, the average of kit As measurements was a linear function of the average of XRF measurements ($r^2 = 0.69$). Taking into account that the kit overestimates water As concentrations by about a factor of two, the relationship suggests that about a quarter of the As in paddy soil is released in the kit’s reaction vessel. Using the relationship and considering XRF measurements as the reference, the 12-sample average determined correctly whether soil As was above or below a 30 mg/kg threshold in 86\% of cases where soil As was above the threshold and in 79\% of cases where soil As was below the threshold. We also used a Bayesian approach using 12 kit measurements to estimate the probability that soil As was above a given threshold indicated by XRF measurements. The Bayesian approach is theoretically optimal but was only slightly more accurate than the linear regression. These results show that rice farmers can identify high-As portions of their fields for mitigation using a dozen field kit measurements on fresh soil and base their decisions on this information.},
  doi = {10.1016/j.geoderma.2020.114755},
  keywords = {Field kit, Rice paddy, Irrigation, Arsenic}
}
</code></pre>

<a name="FiatIJCAR20"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#FiatIJCAR20">FiatIJCAR20</a>,
  author = {Cl\'ement Pit--Claudel and Peng Wang and Benjamin Delaware and Jason Gross and Adam Chlipala},
  title = {Extensible Extraction of Efficient Imperative Programs with Foreign Functions, Manually Managed Memory, and Proofs},
  booktitle = {Proceedings of the \href{https://ijcar2020.org/}{9th International Joint Conference on Automated Reasoning (IJCAR'20)}\},
  month = {June},
  year = {2020},
  location = {Paris, France},
  doi = {10.1007/978-3-030-51054-1_7},
  editor = {Peltier, Nicolas and Sofronie-Stokkermans, Viorica},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {119--137},
  abstract = {We present an original approach to sound program extraction in a proof assistant, using syntax-driven automation to derive correct-by-construction imperative programs from nondeterministic functional source code. Our approach does not require committing to a single inflexible compilation strategy and instead makes it straightforward to create domain-specific code translators. In addition to a small set of core definitions, our framework is a large, user-extensible collection of compilation rules each phrased to handle specific language constructs, code patterns, or data manipulations. By mixing and matching these pieces of logic, users can easily tailor extraction to their own domains and programs, getting maximum performance and ensuring correctness of the resulting assembly code.
    
    Using this approach, we complete the first proof-generating pipeline that goes automatically from high-level specifications to assembly code. In our main case study, the original specifications are phrased to resemble SQL-style queries, while the final assembly code does manual memory management, calls out to foreign data structures and functions, and is suitable to deploy on resource-constrained platforms. The pipeline runs entirely within the Coq proof assistant, leading to final, linked assembly code with overall full-functional-correctness proofs in separation logic.},
  isbn = {978-3-030-51054-1}
}
</code></pre>

<a name="FiatSNAPL17"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#FiatSNAPL17">FiatSNAPL17</a>,
  author = {Adam Chlipala and Benjamin Delaware and Samuel Duchovni and Jason Gross and Cl\'ement Pit--Claudel and Sorawit Suriyakarn and Peng Wang and Katherine Ye},
  title = {The End of History? Using a Proof Assistant to Replace Language Design with Library Design},
  booktitle = {Proceedings of the \href{https://snapl.org/2017/}{The 2nd Summit oN Advances in Programming Languages (SNAPL'17)}\},
  month = {May},
  year = {2017},
  location = {Asilomar, CA, USA},
  abstract = {Functionality of software systems has exploded in part because of advances in programming-language support for packaging reusable functionality as libraries.  Developers benefit from the uniformity that comes of exposing many interfaces in the same language, as opposed to stringing together hodgepodges of command-line tools.  Domain-specific languages may be viewed as an evolution of the power of reusable interfaces, when those interfaces become so flexible as to deserve to be called programming languages.  However, common approaches to domain-specific languages give up many of the hard-won advantages of library-building in a rich common language, and even the traditional approach poses significant challenges in learning new APIs.  We suggest that instead of continuing to develop new domain-specific languages, our community should embrace library-based ecosystems within very expressive languages that mix programming and theorem proving.  Our prototype framework Fiat, a library for the Coq proof assistant, turns languages into easily comprehensible libraries via the key idea of modularizing \emph{functionality} and \emph{performance} away from each other, the former via \emph{macros that desugar into higher-order logic} and the latter via \emph{optimization scripts} that derive efficient code from logical programs.},
  doi = {10.4230/LIPIcs.SNAPL.2017.3},
  pages = {3:1--3:15},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn = {978-3-95977-032-3},
  issn = {1868-8969},
  volume = {71},
  editor = {Benjamin S. Lerner and Rastislav Bod{\'i}k and Shriram Krishnamurthi},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address = {Dagstuhl, Germany},
  urn = {urn:nbn:de:0030-drops-71233},
  keywords = {domain-specific languages, synthesis, verification, proof assistants, software development},
  url = {<a href="https://jasongross.github.io/papers/FiatSNAPL17.pdf">https://jasongross.github.io/papers/FiatSNAPL17.pdf</a>}
}
</code></pre>

<a name="coqpl-21-reification-by-type-inference"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#coqpl-21-reification-by-type-inference">coqpl-21-reification-by-type-inference</a>,
  title = {A Limited Case for Reification by Type Inference},
  author = {Jason Gross},
  month = {January},
  note = {Presented at \href{https://popl21.sigplan.org/home/CoqPL-2021}{The Seventh International Workshop on Coq for Programming Languages (CoqPL'21)}\},
  year = {2021},
  abstract = {Proof by reflection is a common and well-studied automation tool.
    Reification---generally written using $\mathcal{L}_{\text{\textit{tac}\}}$, OCaml, typeclasses, or canonical structures---is the means by which a structured representation is derived from an unstructured representation.
    The reflective automation then operates on the structured representation, relying on an interpretation or denotation function to justify a correspondence between the structured and unstructured representations.
    
    A couple of years ago, I presented a trick for blazing fast reification in two lines of $\mathcal{L}_{\text{\textit{tac}\}}$---using the \texttt{pattern} tactic---which I termed reification by parametricity.
    While I still advocate for parametricity as the preferred method of domain-specific reification, I would like to present here yet another method.
    
    While reification typically requires meta-programming features, I was surprised and delighted to discover that, in some restricted cases, reification can be performed entirely by a combination of the notation system and type inference.
    In some sense, this is trivial: by redefining the basic syntactic notations, a term can be ``reified'' merely by writing the same symbols in another scope.
    In another sense, though, this trick is quite surprising: we use the notation system merely to insert ``reify here'' functions at every atom, and the reification itself is in fact performed by type inference.
    My hope is that the audience will walk away with this new trick in their toolbox, and that some day some problem will come along demanding a slight generalization of this trick, and that generalization will be new and interesting in its own right.
    This, after all, is how reification by parametricity was discovered.
    
    I propose to present the one example I have for this trick: reifying the type structure of a function in a way that allows manipulations of the arguments, such as uncurrying, reassociation of the uncurried structure, and reordering.
    I will present the simple code for this example in detail.
    My goal will be that the audience understand completely how it works, why it works, and how it might be used elsewhere.},
  url = {<a href="https://jasongross.github.io/papers/2021-reification-by-type-inference-coqpl.pdf">https://jasongross.github.io/papers/2021-reification-by-type-inference-coqpl.pdf</a>}
}
</code></pre>

<a name="Gross2021thesis"></a>
<pre class="language-bibtex"><code>@phdthesis{<a href="{{ "/publications/" | relative_url }}#Gross2021thesis">Gross2021thesis</a>,
  author = {Jason S. Gross},
  school = {Massachusetts Institute of Technology},
  title = {Performance Engineering of Proof-Based Software Systems at Scale},
  year = {2021},
  month = feb,
  type = {\{PhD} Thesis},
  abstract = {Formal verification is increasingly valuable as our world comes to rely more on software for critical infrastructure.
    A significant and understudied cost of developing mechanized proofs, especially at scale, is the computer performance of proof generation.
    This dissertation aims to be a partial guide to identifying and resolving performance bottlenecks in dependently typed tactic-driven proof assistants like Coq.
    
    We present a survey of the landscape of performance issues in Coq, with micro- and macro-benchmarks.
    We describe various metrics that allow prediction of performance, such as term size, goal size, and number of binders, and note the occasional surprising lack of a bottleneck for some factors, such as total proof term size.
    To our knowledge such a roadmap to performance bottlenecks is a new contribution of this dissertation.
    
    The central new technical contribution presented by this dissertation is a reflective framework for partial evaluation and rewriting, already used to compile a code generator for field-arithmetic cryptographic primitives which generates code currently used in Google Chrome.
    We believe this prototype is the first scalably performant realization of an approach for code specialization which does not require adding to the trusted code base.
    Our extensible engine, which combines the traditional concepts of tailored term reduction and automatic rewriting from hint databases with on-the-fly generation of inductive codes for constants, is also of interest to replace these ingredients in proof assistants' proof checkers and tactic engines.
    Additionally, we use the development of this framework itself as a case study for the various performance issues that can arise when designing large proof libraries.
    We also present a novel method of simple and fast reification, developed and published during this PhD.
    
    Finally, we present additional lessons drawn from the case studies of a category-theory library, a proof-producing parser generator, and cryptographic code generation.},
  url = {<a href="https://jasongross.github.io/papers/2021-JGross-PhD-EECS-Feb2021.pdf">https://jasongross.github.io/papers/2021-JGross-PhD-EECS-Feb2021.pdf</a>}
}
</code></pre>

<a name="rewriting"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#rewriting">rewriting</a>,
  author = {Jason Gross and Andres Erbsen and Jade Philipoom and Miraya Poddar-Agrawal and Adam Chlipala},
  booktitle = {Proceedings of the \href{https://itpconference.github.io/ITP22/}{13th International Conference on Interactive Theorem Proving (ITP 2022)}\},
  title = {Accelerating Verified-Compiler Development with a Verified Rewriting Engine},
  year = {2022},
  address = {Dagstuhl, Germany},
  editor = {June Andronick and Leonardo de Moura},
  month = {August},
  pages = {17:1--17:18},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  volume = {237},
  abstract = {Compilers are a prime target for formal verification, since compiler bugs invalidate higher-level correctness guarantees, but compiler changes may become more labor-intensive to implement, if they must come with proof patches. One appealing approach is to present compilers as sets of algebraic rewrite rules, which a generic engine can apply efficiently. Now each rewrite rule can be proved separately, with no need to revisit past proofs for other parts of the compiler. We present the first realization of this idea, in the form of a framework for the Coq proof assistant. Our new Coq command takes normal proved theorems and combines them automatically into fast compilers with proofs. We applied our framework to improve the Fiat Cryptography toolchain for generating cryptographic arithmetic, producing an extracted command-line compiler that is about 1000× faster while actually featuring simpler compiler-specific proofs.},
  annote = {Keywords: compiler verification, rewriting engines, cryptography},
  arxiv-url = {<a href="https://arxiv.org/abs/2205.00862">https://arxiv.org/abs/2205.00862</a>},
  doi = {10.4230/LIPIcs.ITP.2022.17},
  eprint = {2205.00862},
  isbn = {978-3-95977-252-5},
  issn = {1868-8969},
  url = {<a href="https://jasongross.github.io/papers/2022-rewriting-itp.pdf">https://jasongross.github.io/papers/2022-rewriting-itp.pdf</a>},
  urn = {urn:nbn:de:0030-drops-167262}
}
</code></pre>

<a name="2022-itp-coq-bug-minimizer"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#2022-itp-coq-bug-minimizer">2022-itp-coq-bug-minimizer</a>,
  author = {Jason Gross and Théo Zimmermann and Miraya Poddar-Agrawal and Adam Chlipala},
  booktitle = {Proceedings of the \href{https://itpconference.github.io/ITP22/}{13th International Conference on Interactive Theorem Proving (ITP 2022)}\},
  title = {Automatic Test-Case Reduction in Proof Assistants: A Case Study in {C}oq},
  year = {2022},
  address = {Dagstuhl, Germany},
  editor = {June Andronick and Leonardo de Moura},
  month = {August},
  pages = {18:1--18:18},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  volume = {237},
  abstract = {As the adoption of proof assistants increases, there is a need for efficiency in identifying, documenting, and fixing compatibility issues that arise from proof-assistant evolution.  We present the Coq Bug Minimizer, a tool for \emph{reproducing buggy behavior} with \emph{minimal} and \emph{standalone} files, integrated with coqbot to trigger \emph{automatically} on failures from Coq's reverse dependency compatibility testing.  Our tool eliminates the overhead of having to download, set up, compile, and then explore and understand large developments, enabling Coq developers to easily obtain modular test-case files for fast experimentation.  In this paper, we describe insights about how test-case reduction is different in Coq than in traditional compilers.
    We expect that our insights will generalize to other proof assistants.  We evaluate the Coq Bug Minimizer on over 150 compatibility testing failures.  Our tool succeeds in reducing failures to smaller test cases roughly 75\% of the time.  The minimizer produces a fully standalone test case 89\% of the time, and it is on average about one-third the size of the original test.  The average reduced test case compiles in 1.25 seconds, with 75\% taking under half a second.},
  annote = {Keywords: debugging, automatic test-case reduction, Coq, bug minimizer},
  doi = {10.4230/LIPIcs.ITP.2022.18},
  isbn = {978-3-95977-252-5},
  issn = {1868-8969},
  url = {<a href="https://jasongross.github.io/papers/2022-coq-bug-minimizer-itp.pdf">https://jasongross.github.io/papers/2022-coq-bug-minimizer-itp.pdf</a>},
  urn = {urn:nbn:de:0030-drops-167273}
}
</code></pre>

<a name="superlinear-slowness"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#superlinear-slowness">superlinear-slowness</a>,
  author = {Jason Gross and Andres Erbsen},
  month = {August},
  note = {Presented at \href{https://coq-workshop.gitlab.io/2022/}{The Coq Workshop 2022}\},
  title = {10 Years of Superlinear Slowness in {C}oq},
  year = {2022},
  abstract = {In most programming languages, asymptotic performance issues can almost always be explained by reference to the algorithm being implemented.
    At most, the standard asymptotic performance of explicitly used operations on chosen data structures must be considered.
    Even the constant factors in performance bottlenecks can often be explained without reference to the implementation of the interpreter, compiler, nor underlying machine.
    
    In 10+ years of working with Coq, we (Jason, Andres, and our colleagues) have found this pattern, which holds across multiple programming languages, to be the exception rather than the rule in Coq!
    This turns performant proof engineering, especially performant proof automation engineering, from straightforward science into unpredictable and fragile guesswork.
    
    By presenting in detail a sampling of examples, we propose a defense of the thesis:
    \emph{Performance bottlenecks in proof automation almost always result from inefficiencies in parts of the system which are conceptually distant from the theorem being proven.}
    Said another way, \emph{debugging, understanding, and fixing performance bottlenecks in automated proofs almost always requires extensive knowledge of the proof engine, and almost never requires any domain-specific knowledge of the theorem being proven}.
    Further, there is no clear direction of improvement:
    We know of no systematic proposal, nor even folklore among experts, of what primitives and performance characteristics are sufficient for a performant proof engine.
    
    We hope to start a discussion on the obvious corollary of this thesis: \emph{This should not be!}
    
    Our presentation, we hope, will serve as a call for a POPLMark for Proof Engines, a call for designing and implementing a proof engine for \emph{scalable performant modular proof automation}.},
  url = {<a href="https://jasongross.github.io/papers/2022-superlinear-slowness-coq-workshop.pdf">https://jasongross.github.io/papers/2022-superlinear-slowness-coq-workshop.pdf</a>}
}
</code></pre>

<a name="CryptoptPLDI23"></a>
<pre class="language-bibtex"><code>@inproceedings{<a href="{{ "/publications/" | relative_url }}#CryptoptPLDI23">CryptoptPLDI23</a>,
  author = {Joel Kuepper and Andres Erbsen and Jason Gross and Owen Conoly and Chuyue Sun and Samuel Tian and David Wu and Adam Chlipala and Chitchanok Chuengsatiansup and Daniel Genkin and Markus Wagner and Yuval Yarom},
  title = {Crypt{O}pt: Verified Compilation with Random Program Search for Cryptographic Primitives},
  booktitle = {PLDI'23: Proceedings of the \href{https://pldi23.sigplan.org/}{44th ACM SIGPLAN Conference on Programming Language Design and Implementation}\},
  month = {June},
  year = {2023},
  location = {Orlando, FL, USA},
  note = {Distinguished Paper Award},
  abstract = {Most software domains rely on compilers to translate high-level code to multiple different machine languages, with performance not too much worse than what developers would have the patience to write directly in assembly language. However, cryptography has been an exception, where many performance-critical routines have been written directly in assembly (sometimes through metaprogramming layers). Some past work has shown how to do formal verification of that assembly, and other work has shown how to generate C code automatically along with formal proof, but with consequent performance penalties vs. the best-known assembly. We present Cryptopt, the first compilation pipeline that specializes high-level cryptographic functional programs into assembly code significantly faster than what GCC or Clang produce, with mechanized proof (in Coq) whose final theorem statement mentions little beyond the input functional program and the operational semantics of x86-64 assembly. On the optimization side, we apply randomized search through the space of assembly programs, with repeated automatic benchmarking on target CPUs. On the formal-verification side, we connect to the Fiat Cryptography framework (which translates functional programs into C-like IR code) and extend it with a new formally verified program-equivalence checker, incorporating a modest subset of known features of SMT solvers and symbolic-execution engines. The overall prototype is quite practical, e.g. producing new fastest-known implementations for the relatively new Intel i9 12G, of finite-field arithmetic for both Curve25519 (part of the TLS standard) and the Bitcoin elliptic curve secp256k1.},
  url = {<a href="http://adam.chlipala.net/papers/CryptoptPLDI23/">http://adam.chlipala.net/papers/CryptoptPLDI23/</a>},
  archiveprefix = {arXiv},
  eprint = {2305.19586},
  arxiv-url = {<a href="https://arxiv.org/abs/2305.19586">https://arxiv.org/abs/2305.19586</a>}
}
</code></pre>

<a name="gross2023scalable"></a>
<pre class="language-bibtex"><code>@article{<a href="{{ "/publications/" | relative_url }}#gross2023scalable">gross2023scalable</a>,
  title = {Towards a Scalable Proof Engine: A Performant Prototype Rewriting Primitive for {C}oq},
  author = {Jason Gross and Andres Erbsen and Jade Philipoom and Rajashree Agrawal and Adam Chlipala},
  journal = {Journal of Automated Reasoning},
  year = {2024},
  month = {Aug},
  day = {14},
  doi = {10.1007/s10817-024-09705-6},
  issn = {1573-0670},
  volume = {68},
  number = {3},
  pages = {19},
  eprint = {2305.02521},
  archiveprefix = {arXiv},
  primaryclass = {cs.PL},
  arxiv-url = {<a href="https://arxiv.org/abs/2305.02521">https://arxiv.org/abs/2305.02521</a>},
  abstract = {We address the challenges of scaling verification efforts to match the increasing complexity and size of systems. We propose a research agenda aimed at building a performant proof engine by studying the asymptotic performance of proof engines and redesigning their building blocks. As a case study, we explore equational rewriting and introduce a novel prototype proof engine building block for rewriting in Coq, utilizing proof by reflection for enhanced performance.
    
    Our prototype implementation can significantly improve the development of verified compilers, as demonstrated in a case study with the Fiat Cryptography toolchain. The resulting extracted command-line compiler is about 1000× faster while featuring simpler compiler-specific proofs. This work lays some foundation for scaling verification efforts and contributes to the broader goal of developing a proof engine with good asymptotic performance, ultimately aimed at enabling the verification of larger and more complex systems.}
}
</code></pre>

<a name="metacoq-quotation-2023"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#metacoq-quotation-2023">metacoq-quotation-2023</a>,
  author = {Jason Gross},
  month = {October},
  note = {Presented remotely to the Gallinette team in Nantes at an informal workshop on meta-programming and modal type theories with native quotation operations},
  title = {Meta{C}oq Quotation: Partial Work Towards {L}öb's Theorem},
  year = {2023},
  presentation-youtube-no-qa = {<a href="https://youtu.be/1MhdPaQMkJY">https://youtu.be/1MhdPaQMkJY</a>}
}
</code></pre>

<a name="gdmi-far-2024"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#gdmi-far-2024">gdmi-far-2024</a>,
  author = {Jason Gross},
  month = {February},
  note = {Presented at \href{https://far.ai/}{FAR AI}'s weekly seminar},
  title = {Guarantees-Driven Mechanistic Interpretability: Formal Proof Size as a Metric for Mechanistic Detail of Understanding},
  year = {2024}
}
</code></pre>

<a name="compact-proofs"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#compact-proofs">compact-proofs</a>,
  author = {Jason Gross and Rajashree Agrawal and Thomas Kwa and Euan Ong and Chun Hei Yip and Alex Gibson and Soufiane Noubir and Lawrence Chan},
  title = {Compact Proofs of Model Performance via Mechanistic Interpretability},
  year = {2024},
  month-old = {June},
  month = {December},
  note = {accepted to \href{https://neurips.cc/Conferences/2024}{The Thirty-Eighth Annual Conference on Neural Information Processing Systems}\},
  note-old = {accepted to the \href{https://icml2024mi.pages.dev/}{ICML 2024 Workshop on Mechanistic Interpretability} (\href{https://openreview.net/forum?id=4B5Ovl9MLE}{Spotlight})},
  published-url-openreview-old = {<a href="https://openreview.net/forum?id=4B5Ovl9MLE">https://openreview.net/forum?id=4B5Ovl9MLE</a>},
  tweet-thread = {<a href="https://twitter.com/diagram_chaser/status/1805337592143265801">https://twitter.com/diagram_chaser/status/1805337592143265801</a>},
  poster-pdf-old = {<a href="https://jasongross.github.io/presentations/icml-2024-mech-interp-workshop/compact-proofs-poster.pdf">https://jasongross.github.io/presentations/icml-2024-mech-interp-workshop/compact-proofs-poster.pdf</a>},
  poster-url = {<a href="https://neurips.cc/virtual/2024/poster/96781">https://neurips.cc/virtual/2024/poster/96781</a>},
  doi = {10.48550/arxiv.2406.11779},
  eprint = {2406.11779},
  arxiv-url = {<a href="https://arxiv.org/abs/2406.11779">https://arxiv.org/abs/2406.11779</a>},
  eprinttype = {arXiv},
  abstract = {We propose using mechanistic interpretability -- techniques for reverse engineering model weights into human-interpretable algorithms -- to derive and compactly prove formal guarantees on model performance.
    We prototype this approach by formally proving accuracy lower bounds for a small transformer trained on Max-of-$K$, validating proof transferability across 151 random seeds and four values of $K$.
    We create 102 different computer-assisted proof strategies and assess their length and tightness of bound on each of our models.
    Using quantitative metrics, we find that shorter proofs seem to require and provide more mechanistic understanding.
    Moreover, we find that more faithful mechanistic understanding leads to tighter performance bounds.
    We confirm these connections by qualitatively examining a subset of our proofs.
    Finally, we identify compounding structureless errors as a key challenge for using mechanistic interpretability to generate compact proofs on model performance.}
}
</code></pre>

<a name="numerical-integration-mi-workshop-2024"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#numerical-integration-mi-workshop-2024">numerical-integration-mi-workshop-2024</a>,
  author = {Chun Hei Yip and Rajashree Agrawal and Jason Gross},
  title = {Re{LU} {MLP}s Can Compute Numerical Integration: Mechanistic Interpretation of a Non-linear Activation},
  note = {accepted to \href{https://icml2024mi.pages.dev/}{ICML 2024 Workshop on Mechanistic Interpretability}\},
  year = {2024},
  month = {June},
  url = {<a href="https://openreview.net/forum?id=rngMb1wDOZ">https://openreview.net/forum?id=rngMb1wDOZ</a>},
  abstract = {Extending the analysis from Nanda et al.\@ (2023) and Zhong et al.\@ (2023), we offer an end-to-end interpretation of the 1 layer MLP-only modular addition transformer model with symmetric embeds.
    We present a clear and mathematically rigorous description of the computation at each layer, in preparation for the proofs-based verification approach as set out in concurrent work under review.
    In doing so, we present a new interpretation of MLP layers: that they implement quadrature schemes to carry out numerical integration, providing anecdotal and mathematical evidence in support.
    This overturns the existing idea that neurons in neural networks are merely on-off switches that test for the presence of ``features'' -- instead multiple neurons can be combined in non-trivial ways to produce continuous quantities.}
}
</code></pre>

<a name="wu2024unifyingverifyingmechanisticinterpretations"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#wu2024unifyingverifyingmechanisticinterpretations">wu2024unifyingverifyingmechanisticinterpretations</a>,
  title = {Unifying and Verifying Mechanistic Interpretations: A Case Study with Group Operations},
  author = {Wilson Wu and Louis Jaburi and Jacob Drori and Jason Gross},
  year = {2024},
  eprint = {2410.07476},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
  month = {October},
  url = {<a href="https://arxiv.org/abs/2410.07476">https://arxiv.org/abs/2410.07476</a>},
  arxiv-url = {<a href="https://arxiv.org/abs/2410.07476">https://arxiv.org/abs/2410.07476</a>},
  doi = {10.48550/arxiv.2410.07476},
  eprint = {2410.07476},
  abstract = {A recent line of work in mechanistic interpretability has focused on reverse-engineering the computation performed by neural networks trained on the binary operation of finite groups.
    We investigate the internals of one-hidden-layer neural networks trained on this task, revealing previously unidentified structure
    and producing a more complete description of such models that unifies the explanations of previous works~(Chughtai et al., 2023; Stander et al., 2024).
    Notably, these models approximate \textit{equivariance} in each input argument.
    We verify that our explanation applies to a large fraction of networks trained on this task by translating it into a \textit{compact proof of model performance}, a quantitative evaluation of model understanding.
    In particular, our explanation yields a guarantee of model accuracy that runs in 30\% the time of brute force and gives a $\geq$95\% accuracy bound for 45\% of the models we trained.
    We were unable to obtain nontrivial non-vacuous accuracy bounds using only explanations from previous works.}
}
</code></pre>

<a name="compact-proofs-iliad2024"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#compact-proofs-iliad2024">compact-proofs-iliad2024</a>,
  title = {Short Formal Proofs of Transformers via Mechanistic Interpretability},
  author = {Jason Gross},
  year = {2024},
  month = {August},
  day = {29},
  note = {Presented at ILIAD Conference, Berkeley, California},
  abstract = {It's possible to formally prove theorems about concrete neural nets --- mechanistic understanding is what allows us to make the proofs short enough to be feasible to construct and check while tightly constraining the actual behavior.
    This framework gives us a quantitative and theoretically grounded metric for measuring the quality of an explanation of neural net behavior.
    We'll present the results from our initial explorations of this agenda (\url{https://www.alignmentforum.org/posts/bRsKimQcPTX3tNNJZ/compact-proofs-of-model-performance-via-mechanistic}), and bridge into discussing exciting future directions and ongoing work in making models more interpretable via fine-tuning on partial explanations.}
}
</code></pre>

<a name="numerical-integration-mlp"></a>
<pre class="language-bibtex"><code>@misc{<a href="{{ "/publications/" | relative_url }}#numerical-integration-mlp">numerical-integration-mlp</a>,
  title = {Modular addition without black-boxes: Compressing explanations of {MLP}s that compute numerical integration},
  author = {Chun Hei Yip and Rajashree Agrawal and Lawrence Chan and Jason Gross},
  year = {2024},
  month = {December},
  eprint = {2412.03773},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
  abstract = {The goal of mechanistic interpretability is discovering simpler, low-rank algorithms implemented by models.
    While we can compress activations into features, compressing nonlinear feature-maps---like MLP layers---is an open problem.
    In this work, we present the first case study in rigorously compressing nonlinear feature-maps, which are the leading asymptotic bottleneck to compressing small transformer models.
    We work in the classic setting of the modular addition models, and target a non-vacuous bound on the behaviour of the ReLU MLP in time linear in the parameter-count of the circuit.
    To study the ReLU MLP analytically, we use the infinite-width lens, which turns post-activation matrix multiplications into approximate integrals.
    We discover a novel interpretation of the MLP layer in one-layer transformers implementing the ``pizza'' algorithm: the MLP can be understood as evaluating a quadrature scheme, where each neuron computes the area of a rectangle under the curve of a trigonometric integral identity.
    Our code is available at \url{https://tinyurl.com/mod-add-integration}.},
  url = {<a href="https://arxiv.org/abs/2412.03773">https://arxiv.org/abs/2412.03773</a>}
}
</code></pre>




<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.99.</em></p>
