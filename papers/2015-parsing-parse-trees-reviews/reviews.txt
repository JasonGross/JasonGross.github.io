			OveMer	RevExp
Review #76A		1	4
Review #76B		2	3
Review #76C		3	3
Review #76D		2	4
Review #76E		2	4
(1 = Reject, 4 = Accept; 3 = Knowledgeable, 4 = Expert)

===========================================================================
                           ICFP '15 Review #76A
---------------------------------------------------------------------------
Paper #76: Parsing Parses: A Pearl of (Dependently Typed) Programming and
           Proof
---------------------------------------------------------------------------


                      Overall merit: 1. Reject
                 Reviewer expertise: 4. Expert

                         ===== Paper summary =====

This paper proposes a CF parsing algorithm schema in Coq, together
with soundness and completeness proofs.

                          ===== Evaluation =====

The proposed approach to proving parsing (and parsing itself) appears
very weird and the presentation is obscure. I can only
recommend rejection.

1. Here are some questions that have arisen, but were not answered,
   upon reading your paper:

- Splitting oracles: the essential algorithmic component of parsing is
  the association of the input into meaningful trees. Deferring the
  split choice to an "oracle" means that all non-trivial computation
  is in it. So I would not say that you're performing parsing.

- The work that remains appear to be mostly about detection of
  recursion in the grammar, which is easier than the above step.

- The textbook approach to detect loops is by reduction to Chomsky
  Normal Form. (This can be done statically on the grammar.) In
  comparison your approach feels awkward. At the minimum, discuss
  your choice!

- I don't think that your interface to the parser is sensible. Why is
  it so long (fig 1)? In my mind I should just supply the grammar
  rules. (And perhaps your oracle.) I can also not reconcile your
  explanation (reading it off the minimal parse tree) with fig 1.

- An underscored "insight" seems to be about the instantiation of type
  variables to get soundness and completeness. I do not get why you
  proceed as such.

  The obvious approach seems to be:

  1. Define a "ParseTreeOf nt s" (the spec)
  2. Write an algorithm to decide the relation:

     parse : (nt : NT) -> (s : String) -> Decide (MinParseTreeOf ns t)

  And to get to the ParseTreeOf version only the de-loop lemma is
  needed (in one direction).

  There is some discussion in the later sections about how you failed
  to produce something sensible at the first attempt, but I could not
  understand it. It also seems like you've presented (parts of) your
  search for the right solution in the paper. I think this only serves
  to obscure your point.

2. If you propose a programming pearl, showing the code in a
meaningful order is the minimum you should do. Here we see lots of
type signatures, but one must always double check if they're supposed
to introduce an inductive type, a function, be a constructor, an
assumption, etc.

                    ===== Comments for author(s) =====

For this paper to become a pearl it needs much simplification and
cleaning. I suggest a possible direction above. In any case you must
discuss the obvious paths somewhere.

===========================================================================
                           ICFP '15 Review #76B
---------------------------------------------------------------------------
Paper #76: Parsing Parses: A Pearl of (Dependently Typed) Programming and
           Proof
---------------------------------------------------------------------------


                      Overall merit: 2. Weak reject
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

This paper reports a formalization of a functional parser for
context-free grammars in Coq. Two novelties of the paper are that 1)
the parser is parameterised over a splitting oracle that provides a
list of candidate ways to split strings to be parsed and that 2) the
parser 'parametrically polymorphically' supports three modes of
returning Booleans -- either parsing succeeds or fails, returning a parse
tree or None, or returning a disjoint union of either a parse tree or
a proof that it is impossible that there is a parse tree. 
There has been a closely related work of proving essentially the same algorithm 
in HOL4.

                          ===== Evaluation =====

The paper is well-written. The authors deliver the technical ideas
smoothly by nicely mixing mathematical notations and Coq codes. 
I appreciate this aspect highly as it is nontrivial to write a paper on
formalization in a proof assistant without exposing a lot of codes. 
I found the idea of parameterising a parser over splitters interesting. However,
I did not find that the rest of the development is appealing
enough in elegance or in instructiveness to warrant an ICFP pearl. 
I had problems in matching the paper to the accompanying Coq
codes. (E.g., grep could not find has_parse or min_parse -- I was
interested in a proof of min_parse.) I miss technical comparisons
with the work by Ridge in HOL4. The authors say their approach is different from Ridge's in that they use dependent types which have a different aesthetic appeal 
-- the statement is too general to be informative. Perhaps, section 5.1 could be
expanded to make a stronger case for having a parser prove its own soundness.

                    ===== Comments for author(s) =====

Page 2, left, Section 1.2, line 6:
current current

Page 4, right, 1st paragraph, line 5:
where ⊤ is the one constructor of -> where () is

===========================================================================
                           ICFP '15 Review #76C
---------------------------------------------------------------------------
Paper #76: Parsing Parses: A Pearl of (Dependently Typed) Programming and
           Proof
---------------------------------------------------------------------------


                      Overall merit: 3. Weak accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

The paper describes a dependently-typed development, in Coq, of parsing for context free grammars, modelled on the development by Ridge in HOL4 (reference 11 of the current paper). That work in particular introduces the mechanism by which non-terminating searches for parses are avoided, as necessitated by working in a total environment.

The novelty of this paper is to implement the algorithm at a sufficient level of generality that the process of parsing is applied to parse trees themselves in order to guarantee termination as well as completeness.

The paper contains a running example of parsing "abab" in the grammar (ab)*. It also covers the related literature, and reflects on the development.

                          ===== Evaluation =====

The paper is interesting, and presents a result and a style of development that should be disseminated. It has a number of drawbacks, however.

At a general level, the presentation is somewhat austere, and the key section amounts to talking through the details of a highly parametrised, dependently-typed, interface, presented in Figure 1 (which occupies a whole page). The authors try hard to illustrate aspects of this with examples (the running example of (ab)*) and discussion, but it is most likely in the very nature of the work that this kind of description is necessary. The difficulty of this is exacerbated by the fact that it's a textual document: what I was wanting to see was a set of versions of increasing complexity (with diffs indicated) that gave more of an indication of the way in which the development had proceeded.

The work is also incomplete in a number of ways
 - there is a substantial amount to do on defining splitters and their effect on performance (more discussion on splitters below); this is reported as planned work;
 - some aspects of the formal development are not done, e.g. the parser extensionality axiom from Subsection 5.3 (this is discussed in Section 9, p10), and the "facts" cited in 5.1 (which are proved in the Coq code)

The treatment of splitters was confusing.
 - When splitting a parse tree, there is a clearly defined split function defined on p6 column 2;
 - when splitting strings, this is not the case and it was not clear (at least to me) that for every grammar a splitter of the right kind exists; if that is the case it should be stated, and also what the requirements are on an split function in general: some properties are mentioned in 5.1 for splitting parse trees, but are these required in general; if nat, are there any general requirements and existence theorems for functions meeting those requirements?

The reflections in Section 7 are illuminating, and are one of the contributions of the paper. They reflect on the way that the language and constructs of Coq were used by the authors, in particular reflecting the general theme of "what is the right abstraction level, when?". What were missing were any comments on the tools that they used: did editors and any other tools support the development, or not?

In the introduction it is stated "the job of a parse is to decompose a flat list of characters …" often "tokens" are used rather than characters.

highrope -> tightrope (p9)

current current -> current (p2)

                    ===== Comments for author(s) =====

Comments as above.

===========================================================================
                           ICFP '15 Review #76D
---------------------------------------------------------------------------
Paper #76: Parsing Parses: A Pearl of (Dependently Typed) Programming and
           Proof
---------------------------------------------------------------------------


                      Overall merit: 2. Weak reject
                 Reviewer expertise: 4. Expert

                         ===== Paper summary =====

Authors present the implementation of parser for context-free grammars
in Coq. The paper starts with describing the problem of infinite regress and
gives a solution to that by denying some shapes of parse trees, namely
cyclic ones. Then some standard notions of CFGs and parse trees are
given. Paper shows how to instantiate the general parse function to
get different kinds of parsers. Finally, the sound and complete parser
is derived.

                          ===== Evaluation =====

The approach to proving correctness of the parser is novel and
elegant.  However, I have problems with qualifying this paper as a
pearl. The paper is generally complicated to follow. The chosen
notation for CFGs is not standard and authors make it worse by mixing
CFGs with regular expressions.

First four chapters give a good introduction to the standard notions.
The core of the paper is section 5 and authors do not provide a clear
picture of what is happening and what for until the end of the
section. Only the Subsection 5.4 puts some of the pieces together.

The biggest criticism is about the code. The presented code in the
paper is not intact with the real development which makes it
impossible to really see if the proposed approach is as simple and
elegant as authors claim. I was unable to find functions like
"has_parse", "has_no_parse", "min_parse", "parse_full", 
"parse_sound", "parse_complete", etc.

The code itself must be refactored:
1) 200 chars in line is a bad practice.
2) Comments or self-documenting style would greatly help
understanding.
3) Contents and structure of different modules should be provided.

                    ===== Comments for author(s) =====

You are using provocative statement that parser is proving its
correctness and this is not what is happening. Reader may feel
disappointed after finding that out.


At page 2 you say that your strategy works only with finite sets of
nonterminals.  However, set of nonterminals could be infinite, but
then you should add the step of extracting the "used" nonterminals
from the grammar.


At page 2 (left column) "current current" => "current"


At page 2 (right column) s = 'ch' => s = "ch"


Your approach to proving correctness IS elegant, but still let the
readers make their mind -- self assessment is not strictly necessary
through the paper.


At page 3 (left column), I think that ParseTree is defined incorrectly
it should be something like:

{ (nt, s), t : nt \in Nonterminal, s \in String, t \in ParseTreeOf nt s }

otherwise the first projection of ParseTree would not give you (nt, s)
as you required by parse_sound function.


In subsection 2.3 it would be nice if you would make precise which
parse tree is returned by the parser for ambiguous grammars. In that
sense your notion of "completeness" is very special.


At page 5, formal definition of ParseQuery is important here.


At page 6 (left column), "proofy" => "proof"


At page 6 (right column), "=" symbol is over the border.


The paper is about CFGs, but you have chosen the regular expression as
your running example.

The chosen notation is complicated to follow.
Would not the standard notation of CFGs be better? (A -> BC, s \in L(G), etc.)

===========================================================================
                           ICFP '15 Review #76E
---------------------------------------------------------------------------
Paper #76: Parsing Parses: A Pearl of (Dependently Typed) Programming and
           Proof
---------------------------------------------------------------------------


                      Overall merit: 2. Weak reject
                 Reviewer expertise: 4. Expert

                         ===== Paper summary =====

The paper describes a correctness proof for a variant of one of
Ridge's parsing algorithms. The authors construct the parser in a
rather general way, and instantiate it so that it can parse parse
trees, generating potentially smaller parse trees that (provably)
satisfy a certain condition. These potentially smaller parse trees are
used to show that another instantiation of the parser is complete
(always finds a parse when there is one).

I like the basic idea of the paper: reusing the parser in the parser's
correctness proof. I can't recall having seen this technique before.
However, I do have a question: How does the proof in the paper compare
to Ridge's original proof? Is it shorter? Longer? Less or more
complicated? There is no discussion of this in the paper.

The paper is accompanied by Coq source code. However, there is no road
map describing the code, there are very few comments in the code, and
the code and the paper use different names. The code type-checks, but
I don't know if it implements the right thing. I suggest that the
authors should take a look at "How to publish research accompanied by
mechanically-checkable proofs" by James Cheney:
http://why-lambda.blogspot.se/2015/01/how-to-publish-research-accompanied-by.html.

I get the feeling that the paper sweeps many details under the rug:

* Type signatures are omitted.
* Pseudocode is used.
* Types are simplified: "The parser has the rough type signature
  [...]".
* Special, overloaded notation is introduced.
* One abstraction (that for strings) is not described.

Perhaps this was done to make the paper more accessible to people who
are not used to dependent types. However, for me it makes the paper
less accessible. I would prefer precise mathematics to pseudocode. I
don't want to guess or infer what's going on. Furthermore, when
programming with dependent types certain details matter, at least if
you want your code to be elegant, and the paper left me wondering what
the actual code looked like (and, as mentioned above, I don't think
that the actual code was very helpful).

In the paper the authors claim that they make use of a "parser
extensionality axiom". (I did not find this axiom in the source code.)
They claim that "Inspection of the code, together with relational
parametricity, validates assuming [the axiom]". Some comments related
to this axiom:

* It's not so easy (for me) to inspect the actual Coq source code.

* I would have preferred if the authors had started from some general
  formulation of relational parametricity, and derived the parser
  extensionality axiom.

* As far as I can see the axiom is completely unnecessary. The authors
  instantiate their general framework in two different ways to end up
  with the following two functions:

    parse        : (nt : Nonterminal) -> (s : String)
                 -> option (ParseTreeOf nt s)
    has_no_parse : (nt : Nonterminal) -> (s : String)
                 -> Unit + (MinParseTreeOf nt s -> Empty)

  The axiom is then used to show that parse and has_no_parse return
  compatible results. I don't see why the authors didn't simply
  instantiate their framework once, to end up with a parse function of
  the following type:

    parse        : (nt : Nonterminal) -> (s : String)
                 -> ParseTreeOf nt s + (MinParseTreeOf nt s -> Empty)

The parser in the paper returns at most one result, even if the
grammar is ambiguous (unlike Ridge's algorithm). I would prefer to get
some warning if a string can be parsed in multiple ways, but this
issue isn't discussed in the paper.

                          ===== Evaluation =====

The paper is advertised as a pearl. However, in my opinion it is too
complicated and not sufficiently elegant to be a pearl. Jeremy Gibbons
instructs reviewers of pearls to "stop reading when [...] the material
gets too complicated [...]", but instead of stopping I evaluated the
paper as a regular research paper.

I like the paper's key idea, and I suspect that it is novel. However,
I am not satisfied with how the idea is presented, and I don't think
that the paper should be published in its current form.

                    ===== Comments for author(s) =====

Related work:

* The first page can give the impression that you have invented the
  parsing algorithm used in the paper. I think you should cite Ridge
  much earlier.

* You write that "In the twentieth century, the functional-programming
  world experimented with a variety of approaches to parser
  combinators", and cite a paper from 1992. Parser combinators go back
  at least to the following book:

    Burge
    Recursive Programming Techniques
    1975

* When you write that "A few other past projects have verified parsers
  with proof assistants" you have missed some examples:

    Koprowski and Binsztok
    TRX: A Formally Verified Parser Interpreter
    ESOP 2010 and LMCS 2011

    Danielsson
    Total Parser Combinators
    ICFP 2010

    Firsov and Uustalu
    Certified CYK parsing of context-free languages
    Journal of Logical and Algebraic Methods in Programming 2014

  There may be more.

* You write that "we formalize grammars via natural-deduction
  inference rules, a slightly nonstandard choice". I don't think this
  is non-standard when dependent types are used. For instance, the
  three references in the previous item use this approach to give
  semantics to grammars/parser combinators.

* (M.) Guilhem should be (G.) Moulin (on page 10 and page 11).

More details:

* Print Assumptions informed me that you have used an axiom that is
  not mentioned in the paper: JMeq_eq. I think it is fine to use this
  axiom, but I also think that it should be documented in the paper.

* The grammar in §2.1.1 doesn't match the one in §1.1.

* "Additionally, we will sometimes fold the constructors of
  ParseItemsTreeOf into the (rule) constructors of ParseTreeOf, to
  mimic the natural-deduction trees." No, I don't think that's what
  you do. For certain sequences of items you merge the last two
  ParseItemsTreeOf constructors (one corresponding to cons and one
  corresponding to nil). A similar comment applies to
  MinParseTreeOf/MinItemsTreeOf. I recommend that you avoid this kind
  of abbreviated notation, to make it easier to understand your
  examples.

* When you introduce (rule)_=, please explain that = refers to string
  equality, not equality of string lengths.

* Are you sure that "s1s2 <= s0" is needed in order to prove
  termination?

* "where \top is the one constructor of the one-element type \top" ->
  "where () is...".

* In the second definitions of production_success_< and
  production_success_= you write "it" instead of "its".

* Figure 1: What is "string_part"?

* §5.1: What is "parse_tree_data"? Your implementation of split seems
  to be ill-typed: p2 has type ParseItemsTreeOf its s2, which does not
  match the domain of deloop.

* Figure 2: You forgot a successful case in any_parse.

* I don't think you use your own notation correctly for the parse
  trees in §5.2:

  * You use the notation "s1 \cdot s2 \in nt" instead of the notation
    "s1s2 \in its". Before I understood this I had trouble
    understanding the parse trees.

  * Some rule labels have been put on the wrong rule. For instance,
    the first two instances of ((ab)*(ab)*) should be moved one level
    down in the tree.

  * Rule labels are missing.

* You use \overline{T'} before you have introduced the name properly.

* §5.2.2: "We may consider only the productions for which the parse
  tree associated to the string is well-typed": I don't understand
  this comment. What part of Figure 2 does it refer to? Your splitter,
  introduced in §5.1, removes all the irrelevant cases, doesn't it?

* Please write out \overline{T_m'} explicitly.

* "The parser extensionality axiom states that, for any fixed
  instantiation of split, and any arbitrary instantiations of the rest
  of the interface": I assume that the String type is also fixed.

* You write that "Ridge's parser also has worst-case O(n^5) running
  time in the input-string length". Does "also" imply that your parser
  also has this running time? How did you define your splitter?

* "Dependent types allow more code reuse": Some people would perhaps
  argue that dependent types make it harder to reuse code.
