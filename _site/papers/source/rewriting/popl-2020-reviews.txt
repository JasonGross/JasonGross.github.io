POPL 2020 Paper #176 Reviews and Comments
===========================================================================
Paper #176 A Framework for Building Verified Partial Evaluators


Review #176A
===========================================================================

Overall merit
-------------
D. Strong Reject

Reviewer expertise
------------------
X. Expert

Paper summary
-------------
The paper presents a framework for partial evaluation in the Coq proof
assistant. The key strength of the work is to avoid hooking into the assistant's
kernel, therefore not requiring to extend the trusted code base.  Instead, the
authors combine several concepts to achieve the desired performance expected
from partial evaluation: Reflection, Normalization by Evaluation, term
rewriting; allowing to internalize within the logic of the assistant the
(controlled) reduction of terms. The work is extensible, being capable of
creating partial evaluators from a user's input.

Strengths
---------
The problem is an interesting one, and the solution is appealing since it needs
not to extend the Coq's kernel.

Weaknesses
----------
The presentation still requires significant polishing.

Comments for author
-------------------
The presentation of the work is unsatisfying, and as such I think the work is
not ready to be accepted. Here is an incomplete and unordered list of what could
be done in order to improve the presentation.

- The example in the introduction could be (much) simpler.

- A high level description of the steps applied to a simple example could help
  gain a high level understanding of the approach. From the introduction I
  understand the main ingredients that you use (NbE, reflection, etc), but not
  how they play together to achieve the goal.

- Keep consistent the naming between math and Coq. Right now some names appear
  out of the blue and one has to guess what they correspond to. For instance,
  `eval_decision_tree` is the same as $\varepsilon_\mathsf{dt}$?

- Show the type of the decision trees, in particular of the `Switch`
  constructor.

- Show where are the `Switch`es in the decision tree.

- How should one interpret $\lnot\mathsf{Wildcard} p = something$?


A few questions unrelated to the presentation:

- Would it make sense to compare also the extracted code from the old approach?

- Is not the `Let` constructor missing a binder in $e_2$?



Review #176B
===========================================================================

Overall merit
-------------
D. Strong Reject

Reviewer expertise
------------------
Y. Knowledgeable

Paper summary
-------------
The paper describes a partial evaluator written in Coq that is meant
to be used for specializing libraries, also written in Coq, such as
the Fiat Cryptography library. The partial evaluator is extensible via
rewriting rules. The design of the partial evaluatior leverages Coq's
normalization through by a clever combination of normalization by
evaluation and pattern-matching compilation of the rewrite rules.

Strengths
---------
The overall goal, of creating an extensible partial evaluator with a
small trusted code base, is a good one.

Weaknesses
----------
The paper is poorly structured in that it makes several classic
writing mistakes: 1) diving into details without explaining the
high-level organization of the system, 2) not adequately
differentiating prior work from the new ideas, 3) not allocating
appropriate space to old vs. new ideas, that is, its bad to spend too
much time on background at the expense of the new ideas.  Because of
the above mistakes, the paper does not adequately answer the following
questions:

* What is the high-level organization of the system? What are the
  main components and how do they interact?

* What end-to-end theorems does your partial evaluator satisfy?
  Also, the definitions that those theorems rely on need to
  be in the paper, such as the denotational semantics.

* What language does your partial evaluator take as input?
  (The paper seems to imply that Coq is the input language,
   but then the grammar shown in the paper seems instead
   to be for the simply-typed lambda calculus.)

* What is it like to use your system? What does the client
  provide, exactly? What the complete work-flow for a client
  of your system?

The paper makes many claims that it does not support with evidence:

* "without adding to the trusted code base"
  "It actually allows a smaller trusted base than in
  widely used systems like Coq"

  What code bases exacty are being compared? What are their sizes?
  Doesn't your tool use Coq, so how can it have a small trusted base
  than Coq?

* "Their partial-evaluation method timed out trying to compile code for
  the third most widely used curve (P-384). Additionally, to achieve
  acceptable reduction performance, the library code had to be written
  manually in continuation-passing style. We will demonstrate a new Coq
  library that corrects both weaknesses"

  The evaluation section does not seem to show results for P-384.

* "being easily applied to new partial-evaluation settings."

  The paper does not show any other applications (besides the Fiat
  Cryptography library that it was designed for).

Comments for author
-------------------
page 4

"it takes Coq over 800 hours to verify that two terms are equal, even
when our partially reduced code is only a dozen or so lines long. In
our new framework, it takes only about 0.3 seconds to do the partial
reduction on the given example"

This doesn't seem to be an apples-to-apples comparison.  You're
comparing Coq checking for term equality to running your partial
evaluator... those seem like different things... if they are really
achieving the same thing, that deserves some explanation.

page 5

"The next few sections introduce the ingredients in detail..."

But you haven't said anything yet about the structure of the overall
system. How does all this fit together? What is it like to use your
system?

page 6

"Section 2 Pattern-Matching Compilation and Evaluation"

It seems that this 5-page section is just a review of Marenget
(2008)...  that's way too much space for a background
section... unless some of this section is new stuff, but then those
pieces need to be clearly marked as such!

page 10

"Proving completeness, on the other hand, would require a much more
interesting correctness lemma for compile_rewrites."

Why don't you prove completeness? That seems rather important for
correctness.  Also, for the end-to-end theorems that you do prove, it
would be very helpful to have formal statements of them in the paper.

page 17

I find disturbing this presentation style of giving wrong versions of
things and then slowing correcting them. I'd prefer to see just one
version that's correct.

"subject to natural correctness conditions on the rewrite rules"
What are those conditions? How do you check that they have
been satisfied?

Questions for authorsâ€™ response
---------------------------------
What is the speed of the generated code? Do you have performance
results for that as well?
